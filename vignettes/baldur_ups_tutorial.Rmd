---
title: "Baldur UPS Tutorial"
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Baldur UPS Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# 1. Setup
Here we cover the tutorial of `UPS-DS`.
The `UPS-DS` has one more condition than the `yeast-DS` and has one more replicate in each condition (`yeast-DS` is shown in `vignette("baldur_yeast_tutorial")`).
First we will download the data from *figshare*, then we will do some minor pre-processing, and normalization.
Finally, we will setup the design-, and contrast- matrix.
```{r setup}
library(baldur)
# Packages for pre-processing
library(dplyr, warn.conflicts = FALSE)
library(tidyr)
ups <- read.csv('https://figshare.com/ndownloader/files/35592278?private_link=28e837bfe865e8f13479') %>% 
  # Improved printing
  as_tibble() %>% 
  # Replace 0 with NA
  mutate(
    across(where(is.numeric), na_if, 0)
  ) %>% 
  # Remove rows with NA for the sake of the tutorial
  drop_na() %>% 
  # Change to lower-case column names
  rename_with(tolower, everything()) %>% 
  # Normalize the data
  psrn('identifier')

# Setup the design matrix
ups_design <- model.matrix(~ 0 + factor(rep(1:3, each = 4)))
colnames(ups_design) <- paste0('fmol_', c(25, 50, 100))

# For the contrast, we want to compare all conditions against each other.
# This can easily be achieved with the following:
ups_contrast <- combn(1:3, 2) %>% 
  t()
```
Lets go over the design and contrast matrix.
First, lets not how the design matrix uses subsets of the real columns of each condition:
```{r design}
colnames(ups[-1])
colnames(ups_design)
```
This lets `baldur` easily identify what columns that are of interest and setting up pre-cursors for the sampling.
In addition, `baldur` gets information on the number of conditions there are in the data (i.e., `ncol(ups_design)`) and the number of replicates in each condition (i.e., `colSums(ups_design)`).
Next, the contrast matrix:
```{r contrast}
ups_contrast
```
First, note how the contrast only has two columns; currently `baldur` only allows pair-wise comparisons.
Lets go over the rows, the first row tells us that the first column of the design matrix should be compared against the second.
I.e., the first row means `fmol25 - fmol50`.
The second row shows that the first column should be compared against the third, i.e., `fmol25 - fmol100`.
Finally, the last row shows that the second column should be compared against the third (`fmol50 - fmol100`).

# 2. Trend-partitioning and uncertainty estimation
First, I would like to note that reader that the remainder of the tutorial will look very similar to `vignette("baldur_yeast_tutorial")`.
The next step in `baldur` is to partition the trends in the mean and variance, and then to estimate the uncertainty of each measurement.
If one does not think there are two trends in their data, then that step can (and should) be skipped.
```{r cluster}
# Partition the data and estimate the priors
ups <- ups %>% 
  trend_partitioning(
    design_matrix = ups_design,
    formula = sd ~ mean + c, # Set the formula you want to use for the partitioning
                             # with c being the partitioning variable.
                             # Note the given formula assumes different intercepts
                             # between the two clusters. But could be changed
                             # if e.g., there seems to be a different slope as well
                             # then we would have used formula = sd ~  mean*c
    eps = 0.1,               # Set the size of the integration window around sd.
                             # Note that larger eps will generally push the 
                             # partitioning upwards. Try to not make it to large so that
                             # the integration covers a large amount outside the function domain (0,Inf)
    n = 1000,                # Larger number makes the integration more precis but makes the 
                             # algorithm run slower
    verbose = T              # If the number of points moved at each iteration should be printed
  )

# If we skip the above step we can directly get the uncertainties as follows:
# Fit the gamma regression
gam_sin <- fit_gamma_regression(ups, sd ~ mean)
# Estimate the uncertainty
unc_sin <- estimate_uncertainty(ups, 'identifier', ups_design, gam_sin)
```

The trends before and after partitioning can then be visualized with `plot_gamma_regression`:
```{r plot_gam, fig.width=7.2, fig.height = 5}
plot_gamma_regression(ups, ups_design)
```
and the two individual plots can be plotted with `plot_gamma` and `plot_gamma_partition`.
In addition, we can see that we could have made slight more efforts in changing `eps` since it looks like some of the lower trend is absorbed in the upper trend.
A bit of manual tweaking finds that `eps = 0.275` appears to capture the trends better:
```{r cluster2, fig.width=7.2, fig.height = 5}
ups <- ups %>% 
  trend_partitioning(
    design_matrix = ups_design,
    formula = sd ~ mean + c,
    eps = 0.275,
    n = 1000,
    verbose = T
  )
plot_gamma_regression(ups, ups_design)
```
even though not perfect.
We can then estimate the uncertainty for the partitioned data as follows:
```{r unc}
# Fit the gamma regression
gam_mix <- fit_gamma_regression(ups)
# Get each data points uncertainty
unc_mix <- estimate_uncertainty(ups, 'identifier', ups_design, gam_mix)
```

# 3. Run the sampling procedure
Finally we sample the posterior of each row in the data.
First we sample assuming a single trend, then using the partitioning.
```{r posterior}
# Single trend
sin_results <- ups %>% 
  # Add hyper-priors for sigma
  estimate_gamma_priors(ups_design, gam_sin) %>% 
  # For time purposes we only sample for six rows
  head() %>% 
  sample_posterior(
    'identifier',
    ups_design,
    ups_contrast,
    unc_sin,
    clusters = 1 # I highly recommend increasing the number of parallel workers/clusters
                 # this will greatly reduce the speed of running baldur
  )
# The top hits then looks as follows:
sin_results %>% 
  dplyr::arrange(err)

# Mixed trends
mix_results <- ups %>% 
  # Add hyper-priors for sigma
  estimate_gamma_priors(ups_design, gam_mix) %>% 
  # For time purposes we only sample for six rows
  head() %>% 
  sample_posterior(
    'identifier',
    ups_design,
    ups_contrast,
    unc_mix
  )
# The top hits then looks as follows:
mix_results %>% 
  dplyr::arrange(err)
```
Here `err` is the probability of error, i.e., the two tail-density supporting the null-hypothesis, `lfc` is the estimated log$_2$-fold change, `sigma` is the common variance, and `lp` is the log-posterior.
Columns without suffix shows the mean estimate from the posterior, while the suffixes `_025`, `_50`, and `_975`, are the 2.5, 50.0, and 97.5, percentiles, respectively.
The suffixes `_eff` and `_rhat` are the diagnostic variables returned by `rstan` (please see the Stan manual for details).
In general, a larger `_eff` indicates a better sampling efficiency, and `_rhat` compares the mixing within chains against between the chains and should be smaller than 1.05.
An important difference from `yeast-DS` is that each peptide gets three rows, one for each comparison in the contrast matrix.

# 4. Sampling with parallel computation
`baludr` is very easy to run in parallel and will drastically reduce the running time.
The only thing that needs to be changed is the `clusters` flag:
```{r parellel}
# Single trend
sin_results <- ups %>% 
  # Add hyper-priors for sigma
  estimate_gamma_priors(ups_design, gam_sin) %>% 
  # For time purposes we only sample for 20 rows
  head(20) %>% 
  sample_posterior(
    'identifier',
    ups_design,
    ups_contrast,
    unc_sin,
    clusters = 2
  )

# Mixed trend
mix_results <- ups %>% 
  # Add hyper-priors for sigma
  estimate_gamma_priors(ups_design, gam_mix) %>% 
  # For time purposes we only sample for 20 rows
  head(20) %>% 
  sample_posterior(
    'identifier',
    ups_design,
    ups_contrast,
    unc_mix,
    clusters = 2
  )
```

# 5. Visualization of the results
`baldur` have two ways of visualizing the results 1) plotting sigma vs LFC and 2) Volcano plots.
To plot sigma against LFC we use `plot_sa`:
```{r plotting_sa, fig.show='hold', fig.width=7.2, fig.height = 7.2}
sin_results %>% 
  plot_sa(
    alpha = .05 # Level of significance
  )
mix_results %>% 
  plot_sa(
    alpha = .01, # Level of significance
    lfc = 1      # Add LFC lines
  )
```

While it is hard to see with this few examples, in general a good decision is indicated by a lack of a trend between $\sigma$ and LFC.
To make a volcano plot one uses `plot_volcano` in a similar fashion to `plot_sa`:
```{r plotting_volc, fig.show='hold', fig.width=7.2, fig.height = 7.2}
sin_results %>% 
  plot_volcano(
    alpha = .05 # Level of significance
  )
mix_results %>% 
  plot_volcano(
    alpha = .01, # Level of significance
    lfc = 1      # Add LFC lines
  )
```
