---
title: "Baldur Yeast Tutorial"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Baldur Yeast Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


# 1. Setup
This tutorial is quite fast and on a very simple data set (2 conditions only), for a more complicated tutorial for setup please see `vignette('baldur_ups_tutorial')`.
First we load `baldur` and setup the model dependent variables we need, then normalize the data and add the mean-variance trends.

```r
library(baldur)
# Setup design matrix
yeast_design <- model.matrix(~0+factor(rep(1:2, each = 3)))
colnames(yeast_design) <- paste0('ng', c(50, 100))
# Compare the first and second column of the design matrix
# with the following contrast matrix
yeast_contrast <- matrix(c(-1, 1)

# Since baldur itself does not deal with missing data we remove the
# rows that have missing data for the purpose of the tutorial.
# Else, one would replace the filtering step with imputation but that is outside
# the scope of baldur
yeast_norm <- yeast %>%
  # Remove missing data
  tidyr::drop_na() %>%
  # Normalize data (this might already have been done if imputation was performed)
  psrn('identifier') %>%
  # Add mean-variance trends
  calculate_mean_sd_trends(yeast_design)
```
Importantly, note that the column names of the design matrix are unique subsets of the names of the columns within the conditions:

```r
colnames(yeast)
#> [1] "identifier" "ng50_1"     "ng50_2"     "ng50_3"     "ng100_1"    "ng100_2"    "ng100_3"
colnames(yeast_design)
#> [1] "ng50"  "ng100"
```
This is essential for `baldur` to know which columns to use in calculations and to perform transformations.

# 2. Trend-partitioning and uncertainty estimation
Next is to infer the mixture of the data and to estimate the parameters needed for `baldur`.
First we will setup the needed variables for using `baldur` without partitioning the data.
Then, partitioning and setting up `baldur` after trend-partitioning

```r
# Fit the gamma regression
gr_model <- fit_gamma_regression(yeast_norm, sd ~ mean)
# Estimate the uncertainty
unc_gr <- estimate_uncertainty(gr_model, yeast_norm, 'identifier', yeast_design)
```

# 3. Run the sampling procedure
Finally we sample the posterior of each row in the data.
First we sample assuming a single trend, then using the partitioning.

```r
# Single trend
gr_results <- gr_model %>%
  # Add hyper-priors for sigma
  estimate_gamma_hyperparameters(yeast_norm) %>%
  infer_data_and_decision_model(
    'identifier',
    yeast_design,
    yeast_contrast,
    unc_gr,
    clusters = 10 # I highly recommend using parallel workers/clusters
  )               # this will greatly reduce the speed of running baldur
# The top hits then looks as follows:
gr_results %>%
  dplyr::arrange(err)
#> # A tibble: 1,802 × 21
#>    identifier   compa…¹       err    lfc lfc_025 lfc_50 lfc_975 lfc_eff lfc_r…²  sigma sigma…³ sigma…⁴ sigma…⁵ sigma…⁶
#>    <chr>        <chr>       <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
#>  1 Cre09.g4060… ng100 … 1.92e-229  6.18    5.80   6.18    6.57    2295.   1.00  0.149   0.0816  0.138   0.283    1178.
#>  2 Cre12.g5541… ng100 … 7.70e-180  1.61    1.49   1.61    1.72    3352.   1.00  0.0608  0.0329  0.0555  0.120    1446.
#>  3 sp|P37302|A… ng100 … 2.56e-174  1.51    1.40   1.51    1.62    3197.   0.999 0.0568  0.0306  0.0516  0.113    1304.
#>  4 sp|P38788|S… ng100 … 1.58e-154  1.07    0.994  1.07    1.16    3590.   1.00  0.0442  0.0243  0.0401  0.0861   1289.
#>  5 Cre10.g4207… ng100 … 5.81e-133  4.16    3.81   4.16    4.51    3318.   1.00  0.181   0.103   0.167   0.342    1143.
#>  6 Cre14.g6167… ng100 … 2.09e-126 -4.54   -4.92  -4.54   -4.17    2507.   0.999 0.176   0.0965  0.161   0.342    1266.
#>  7 sp|P09624|D… ng100 … 2.47e-102  1.48    1.34   1.48    1.61    3488.   1.00  0.0708  0.0385  0.0649  0.138    1080.
#>  8 Cre12.g5331… ng100 … 9.54e- 94  1.41    1.27   1.41    1.55    3293.   1.00  0.0720  0.0395  0.0650  0.148    1088.
#>  9 sp|P19882|H… ng100 … 1.59e- 92  0.885   0.799  0.884   0.972   4026.   1.00  0.0499  0.0272  0.0461  0.0944   1637.
#> 10 Cre06.g3065… ng100 … 1.62e- 92  4.20    3.80   4.20    4.62    2418.   1.00  0.185   0.101   0.167   0.368    1270.
#> # … with 1,792 more rows, 7 more variables: sigma_rhat <dbl>, lp <dbl>, lp_025 <dbl>, lp_50 <dbl>, lp_975 <dbl>,
#> #   lp_eff <dbl>, lp_rhat <dbl>, and abbreviated variable names ¹​comparison, ²​lfc_rhat, ³​sigma_025, ⁴​sigma_50,
#> #   ⁵​sigma_975, ⁶​sigma_eff
```
Here `err` is the probability of error, i.e., the two tail-density supporting the null-hypothesis, `lfc` is the estimated log$_2$-fold change, `sigma` is the common variance, and `lp` is the log-posterior.
Columns without suffix shows the mean estimate from the posterior, while the suffixes `_025`, `_50`, and `_975`, are the 2.5, 50.0, and 97.5, percentiles, respectively.
The suffixes `_eff` and `_rhat` are the diagnostic variables returned by `rstan` (please see the Stan manual for details).
In general, a larger `_eff` indicates a better sampling efficiency, and `_rhat` compares the mixing within chains against between the chains and should be smaller than 1.05.

# 4. Running Baldur with Latent Gamma Regression estimation
First we fit the LGMR model:

```r
yeast_lgmr <- fit_lgmr(yeast_norm, lgmr_model, cores = 5)
#> Warning: There were 2 divergent transitions after warmup. See
#> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
#> to find out why this is a problem and how to eliminate them.
#> Warning: Examine the pairs() plot to diagnose sampling problems
```

We can print the model with `print` and extract parameters of interest with `coef`:

```r
print(yeast_lgmr)
#> 
#> LGMR Model
#> 	mu=exp(-1.798251 - 0.3219637 f(bar_y)) + kappa exp(7.06273 - 0.3842551 f(bar_y))
#> 
#>  auxiliary:
#>         mean   se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff  Rhat
#> alpha  4.093  0.004336  0.233  3.651  3.933  4.089  4.246  4.562   2890     1
#> nrmse  0.562  0.000234  0.014  0.534  0.552  0.562  0.571  0.589   3602     1
#> 
#> 
#>  Coefficients:
#>        mean   se_mean      sd    2.5%     25%     50%     75%   97.5%  n_eff  Rhat
#> I    -1.798  0.000425  0.0260  -1.848  -1.816  -1.799  -1.781  -1.747   3744     1
#> I_L   7.063  0.000463  0.0419   6.981   7.034   7.062   7.091   7.145   8183     1
#> S     0.322  0.000280  0.0233   0.276   0.306   0.322   0.338   0.368   6891     1
#> S_L   0.384  0.000271  0.0348   0.316   0.361   0.385   0.407   0.453  16534     1
#> 
#> 
#>  theta:
#>               mean   se_mean      sd      2.5%     25%    50%    75%  97.5%  n_eff  Rhat
#> theta[1]     0.248  1.27e-03  0.2215  0.000620  0.0501  0.190  0.407  0.737  30548     1
#> theta[2]     0.703  2.37e-03  0.2450  0.025826  0.6322  0.771  0.866  0.992  10661     1
#> theta[3]     0.291  1.51e-03  0.2470  0.000526  0.0634  0.237  0.486  0.797  26654     1
#> theta[4]     0.345  1.76e-03  0.2750  0.000698  0.0805  0.310  0.574  0.875  24447     1
#> theta[5]     0.899  6.46e-04  0.0887  0.704461  0.8494  0.915  0.970  1.000  18836     1
#> theta[6]     0.295  1.46e-03  0.2469  0.000704  0.0672  0.244  0.490  0.798  28691     1
#> theta[7]     0.355  1.69e-03  0.2729  0.001059  0.0950  0.323  0.582  0.879  26156     1
#> theta[8]     0.972  1.78e-04  0.0315  0.888133  0.9586  0.984  0.996  1.000  31402     1
#> theta[9]     0.350  1.66e-03  0.2680  0.001127  0.0961  0.323  0.571  0.868  25932     1
#> theta[10]    0.234  1.20e-03  0.2109  0.000501  0.0475  0.176  0.382  0.707  31091     1
#> theta[11]    0.244  1.22e-03  0.2182  0.000468  0.0501  0.187  0.401  0.726  31754     1
#> theta[12]    0.714  2.28e-03  0.2410  0.025466  0.6492  0.782  0.873  0.993  11140     1
#> theta[13]    0.406  2.05e-03  0.2899  0.001175  0.1198  0.413  0.659  0.906  19984     1
#> theta[14]    0.845  1.01e-03  0.1374  0.513257  0.7846  0.869  0.942  0.999  18519     1
#> theta[15]    0.806  1.53e-03  0.1770  0.235088  0.7453  0.842  0.923  0.998  13419     1
#> theta[16]    0.298  1.47e-03  0.2502  0.000794  0.0686  0.245  0.497  0.812  28946     1
#> theta[17]    0.500  2.33e-03  0.2981  0.002379  0.2285  0.560  0.747  0.968  16419     1
#> theta[18]    0.335  1.57e-03  0.2656  0.001118  0.0836  0.294  0.554  0.851  28448     1
#> theta[19]    0.287  1.43e-03  0.2460  0.000587  0.0607  0.232  0.478  0.805  29428     1
#> theta[20]    0.492  2.27e-03  0.2960  0.002392  0.2206  0.547  0.736  0.963  17065     1
#> theta[21]    0.469  2.24e-03  0.2971  0.002220  0.1858  0.514  0.719  0.950  17672     1
#> theta[22]    0.351  1.64e-03  0.2714  0.001070  0.0909  0.322  0.576  0.877  27436     1
#> theta[23]    0.898  6.39e-04  0.0921  0.688359  0.8477  0.916  0.971  1.000  20755     1
#> theta[24]    0.980  1.35e-04  0.0238  0.915243  0.9710  0.989  0.997  1.000  31116     1
#> theta[25]    0.289  1.47e-03  0.2470  0.000770  0.0622  0.235  0.481  0.805  28278     1
#> theta[26]    0.295  1.46e-03  0.2477  0.000623  0.0665  0.246  0.488  0.805  28801     1
#> theta[27]    0.333  1.63e-03  0.2650  0.000918  0.0839  0.292  0.551  0.856  26497     1
#> theta[28]    0.539  2.38e-03  0.2944  0.003789  0.2990  0.613  0.774  0.976  15243     1
#> theta[29]    0.365  1.81e-03  0.2781  0.001003  0.0967  0.341  0.602  0.892  23524     1
#> theta[30]    0.235  1.20e-03  0.2118  0.000478  0.0464  0.179  0.383  0.712  31023     1
#> theta[31]    0.302  1.48e-03  0.2492  0.000784  0.0705  0.254  0.502  0.804  28278     1
#> theta[32]    0.266  1.29e-03  0.2316  0.000577  0.0563  0.210  0.439  0.763  32066     1
#> theta[33]    0.275  1.36e-03  0.2379  0.000450  0.0569  0.220  0.455  0.779  30622     1
#> theta[34]    0.298  1.49e-03  0.2494  0.000857  0.0651  0.248  0.493  0.810  27941     1
#> theta[35]    0.221  1.16e-03  0.2064  0.000382  0.0400  0.162  0.360  0.695  31426     1
#> theta[36]    0.321  1.53e-03  0.2629  0.000746  0.0721  0.276  0.534  0.848  29401     1
#> theta[37]    0.328  1.61e-03  0.2641  0.000861  0.0795  0.286  0.543  0.852  26777     1
#> theta[38]    0.792  1.72e-03  0.1901  0.133937  0.7371  0.832  0.914  0.998  12216     1
#> theta[39]    0.949  3.27e-04  0.0510  0.821642  0.9207  0.965  0.990  1.000  24285     1
#> theta[40]    0.669  2.23e-03  0.2647  0.015069  0.5601  0.742  0.859  0.994  14133     1
#> theta[41]    0.253  1.24e-03  0.2269  0.000460  0.0493  0.193  0.415  0.752  33317     1
#> theta[42]    0.495  2.20e-03  0.2957  0.002741  0.2300  0.550  0.737  0.967  18058     1
#> theta[43]    0.650  2.59e-03  0.2757  0.008907  0.5288  0.733  0.850  0.992  11344     1
#> theta[44]    0.253  1.21e-03  0.2223  0.000532  0.0523  0.199  0.412  0.737  33928     1
#> theta[45]    0.720  2.33e-03  0.2382  0.028461  0.6547  0.786  0.878  0.994  10454     1
#> theta[46]    0.217  1.11e-03  0.1969  0.000468  0.0431  0.161  0.353  0.660  31534     1
#> theta[47]    0.260  1.30e-03  0.2287  0.000637  0.0537  0.202  0.430  0.754  30724     1
#> theta[48]    0.458  2.23e-03  0.2940  0.002060  0.1774  0.496  0.708  0.937  17378     1
#> theta[49]    0.987  9.38e-05  0.0166  0.940634  0.9813  0.993  0.998  1.000  31484     1
#> theta[50]    0.226  1.19e-03  0.2087  0.000421  0.0420  0.167  0.371  0.697  30742     1
#> theta[51]    0.220  1.15e-03  0.1995  0.000488  0.0435  0.167  0.358  0.669  30230     1
#> theta[52]    0.222  1.14e-03  0.2040  0.000423  0.0431  0.165  0.362  0.687  32237     1
#> theta[53]    0.298  1.45e-03  0.2506  0.000723  0.0678  0.244  0.492  0.821  29995     1
#> theta[54]    0.257  1.27e-03  0.2255  0.000584  0.0544  0.201  0.424  0.743  31440     1
#> theta[55]    0.228  1.21e-03  0.2076  0.000416  0.0437  0.171  0.372  0.694  29296     1
#> theta[56]    0.266  1.33e-03  0.2341  0.000608  0.0533  0.208  0.440  0.768  31018     1
#> theta[57]    0.611  2.70e-03  0.2821  0.007761  0.4490  0.703  0.819  0.980  10953     1
#> theta[58]    0.920  5.02e-04  0.0720  0.751690  0.8781  0.936  0.979  1.000  20562     1
#> theta[59]    0.230  1.24e-03  0.2072  0.000456  0.0462  0.175  0.374  0.692  28102     1
#> theta[60]    0.772  1.75e-03  0.2055  0.087432  0.7111  0.819  0.907  0.998  13838     1
#> theta[61]    0.488  2.32e-03  0.2955  0.002847  0.2128  0.548  0.735  0.951  16245     1
#> theta[62]    0.336  1.67e-03  0.2677  0.000671  0.0801  0.296  0.564  0.853  25649     1
#> theta[63]    0.432  2.06e-03  0.2915  0.001776  0.1524  0.447  0.682  0.934  20011     1
#> theta[64]    0.928  4.69e-04  0.0677  0.763547  0.8891  0.945  0.985  1.000  20844     1
#> theta[65]    0.583  2.31e-03  0.2901  0.005056  0.3867  0.660  0.808  0.988  15824     1
#> theta[66]    0.307  1.54e-03  0.2564  0.000620  0.0659  0.258  0.513  0.824  27552     1
#> theta[67]    0.832  1.37e-03  0.1527  0.417954  0.7762  0.859  0.933  0.999  12474     1
#> theta[68]    0.392  2.00e-03  0.2839  0.001225  0.1131  0.386  0.638  0.892  20163     1
#> theta[69]    0.373  1.88e-03  0.2796  0.001201  0.1042  0.352  0.610  0.898  22087     1
#> theta[70]    0.536  2.55e-03  0.2972  0.002595  0.2820  0.620  0.775  0.968  13610     1
#> theta[71]    0.235  1.15e-03  0.2123  0.000410  0.0471  0.178  0.384  0.709  34114     1
#> theta[72]    0.953  3.09e-04  0.0486  0.829097  0.9271  0.968  0.992  1.000  24694     1
#> theta[73]    0.399  1.89e-03  0.2851  0.001217  0.1222  0.395  0.643  0.913  22707     1
#> theta[74]    0.242  1.24e-03  0.2170  0.000502  0.0475  0.184  0.396  0.720  30815     1
#> theta[75]    0.369  1.88e-03  0.2806  0.000903  0.0990  0.345  0.611  0.887  22321     1
#> theta[76]    0.907  5.77e-04  0.0816  0.717470  0.8605  0.923  0.973  1.000  19958     1
#> theta[77]    0.323  1.59e-03  0.2597  0.000787  0.0784  0.282  0.535  0.830  26713     1
#> theta[78]    0.265  1.33e-03  0.2299  0.000574  0.0577  0.212  0.435  0.755  29807     1
#> theta[79]    0.326  1.60e-03  0.2621  0.000877  0.0787  0.284  0.542  0.839  26804     1
#> theta[80]    0.981  1.25e-04  0.0225  0.918715  0.9730  0.990  0.998  1.000  32601     1
#> theta[81]    0.221  1.13e-03  0.2013  0.000540  0.0436  0.169  0.355  0.684  31847     1
#> theta[82]    0.265  1.32e-03  0.2329  0.000641  0.0539  0.209  0.435  0.769  31234     1
#> theta[83]    0.277  1.32e-03  0.2419  0.000501  0.0592  0.220  0.458  0.806  33640     1
#> theta[84]    0.965  2.26e-04  0.0370  0.869203  0.9473  0.978  0.994  1.000  26839     1
#> theta[85]    0.237  1.19e-03  0.2130  0.000572  0.0470  0.181  0.388  0.713  32135     1
#> theta[86]    0.267  1.29e-03  0.2353  0.000594  0.0557  0.209  0.440  0.780  33472     1
#> theta[87]    0.979  1.40e-04  0.0253  0.909219  0.9688  0.988  0.997  1.000  32682     1
#> theta[88]    0.253  1.31e-03  0.2280  0.000482  0.0481  0.194  0.419  0.751  30445     1
#> theta[89]    0.252  1.24e-03  0.2240  0.000496  0.0503  0.195  0.414  0.744  32450     1
#> theta[90]    0.321  1.56e-03  0.2597  0.000884  0.0777  0.281  0.529  0.847  27764     1
#> theta[91]    0.610  2.54e-03  0.2812  0.008012  0.4515  0.696  0.819  0.980  12289     1
#> theta[92]    0.419  2.06e-03  0.2898  0.001404  0.1356  0.434  0.666  0.920  19697     1
#> theta[93]    0.280  1.43e-03  0.2400  0.000656  0.0593  0.225  0.466  0.779  28269     1
#> theta[94]    0.969  2.03e-04  0.0341  0.878924  0.9545  0.982  0.996  1.000  28048     1
#> theta[95]    0.975  1.66e-04  0.0288  0.896034  0.9634  0.986  0.997  1.000  30162     1
#> theta[96]    0.964  2.36e-04  0.0396  0.858912  0.9447  0.977  0.995  1.000  28210     1
#> theta[97]    0.251  1.25e-03  0.2232  0.000460  0.0508  0.191  0.414  0.738  31821     1
#> theta[98]    0.935  4.05e-04  0.0620  0.783845  0.9000  0.951  0.986  1.000  23458     1
#> theta[99]    0.404  2.01e-03  0.2876  0.001411  0.1226  0.406  0.656  0.909  20402     1
#> theta[100]   0.979  1.35e-04  0.0245  0.912257  0.9696  0.988  0.997  1.000  33139     1
#>  [ reached getOption("max.print") -- omitted 1702 rows ]
# Extract the regression, alpha, and theta parameters and the NRMSE.
yeast_lgmr_coef <- coef(yeast_lgmr, pars = c("all"))
```

We can then estimate the uncertainty similar to the GR case:

```r
unc_lgmr <- estimate_uncertainty(yeast_lgmr, yeast_norm, 'identifier', yeast_design)
```

Then running the data and decision model:

```r
# Single trend
lgmr_results <- yeast_lgmr %>%
  # Add hyper-priors for sigma
  estimate_gamma_hyperparameters(yeast_norm) %>%
  infer_data_and_decision_model(
    'identifier',
    yeast_design,
    yeast_contrast,
    unc_lgmr,
    clusters = 10
  )
```

# 5. Visualization of the results
`baldur` have two ways of visualizing the results 1) plotting sigma vs LFC and 2) Volcano plots.
To plot sigma against LFC we use `plot_sa`:

```r
gr_results %>%
  plot_sa(
    alpha = .05, # Level of significance
    lfc = 1      # Add LFC lines
  )

lgmr_results %>%
  plot_sa(
    alpha = .05, # Level of significance
    lfc = 1      # Add LFC lines
  )
```

![plot of chunk plotting_sa](plotting_sa-1yeast.png)![plot of chunk     plotting_sa](plotting_sa-2yeast.png)

While it is hard to see with this few examples, in general a good decision is indicated by a lack of a trend between $\sigma$ and LFC.
To make a volcano plot one uses `plot_volcano` in a similar fashion to `plot_sa`:

```r
gr_results %>%
  plot_volcano(
    alpha = .05, # Level of significance
    lfc = 1      # Add LFC lines
  )

lgmr_results %>%
  plot_volcano(
    alpha = .05, # Level of significance
    lfc = 1      # Add LFC lines
  )
```

![plot of chunk plotting_volc](plotting_volc-1yeast.png)![plot of chunk plotting_volc](plotting_volc-2yeast.png)
